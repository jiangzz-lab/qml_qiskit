{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "from qiskit.circuit.library import GroverOperator\n",
    "from qiskit.quantum_info import Statevector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroverLearner:\n",
    "    ''' \n",
    "    Implement a quanutm reinforcement learning agent based on Grover amplitute enhancement and QLearing algorithm.\n",
    "\n",
    "    Assumption:\n",
    "    The dimensions of the state space and action space are both finite\n",
    "\n",
    "    Parameters:\n",
    "    env: the environment to solve; default is OpenAI gym \"FrozenLake\"\n",
    "    state (int): current state\n",
    "    action (int): current action \n",
    "    state_dimension (int): dimension of the state space\n",
    "    action_dimension (int): dimension of the action space\n",
    "    action_qregister_size (int): number of qubits on the quantum register for storing the action wavefunction \n",
    "    max_grover_length (int): maximum of the length of the grover iteration\n",
    "    Q_values (2D np array): Q values of all (state, action) combinations; shape = (state_dimension, action_dimention)\n",
    "    grover_lengths (2D np array): lengths of grover iterations of all (state, action) combinaitons; shape = (state_dimension, action_dimention)\n",
    "    grover_operators (1D np array): grover_operators for all actions\n",
    "    action_circuits (1D np array): action quantum circuits for all actions\n",
    "    hyperparameters (dict): hyperparameters of learning; \n",
    "                            {\n",
    "                                'k': prefactor of max grover length, \n",
    "                                'alpha': learning rate, 'gamma': discount, \n",
    "                                'epsilonr': tolerance of the Q values,\n",
    "                                'max_epochs': max number of epochs for training,\n",
    "                                'max_steps': max number of steps in every epoch\n",
    "                            }\n",
    "    QSIM: qiskit simulator\n",
    "    '''\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, env) -> None:\n",
    "        pass\n",
    "        \n",
    "    # hyperparameter setter\n",
    "    def set_hyperparameters(self, params):\n",
    "        pass\n",
    "\n",
    "    # initialize the quantum circuits of actions\n",
    "    def _init_action_circuits(self):\n",
    "        pass\n",
    "\n",
    "    # intitialize the grover operators of actions\n",
    "    def _init_grover_operators(self):\n",
    "        pass\n",
    "    \n",
    "    # run grover iterations within one learning step:\n",
    "    def _run_grover_iterations(self):\n",
    "        pass\n",
    "\n",
    "    # update Q value for one round of grover iterations\n",
    "    def _update_Q_values(self):\n",
    "        pass\n",
    "\n",
    "    # train max epochs\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('qiskitenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17d49cc28dac616a7863004e14b04f7102b074af8657a84413b0a8fb3597af77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
